# LMFO AI ‚Äì Pattern Recognition in Real-World Noisy Environments 

<details>
<summary><strong>Table of Contents</strong></summary>

- [Overview](#-overview)
- [Key Features](#-key-features)
- [Real-World Impact](#-real-world-impact)
  - [Predictive Maintenance ‚Äî Risk Analysis & Early Warning](#predictive-maintenance--risk-analysis--early-warning)
  - [Multi-Sector Adaptability](#multi-sector-adaptability)
- [Benchmark Environment & High-Noise Real-World Dataset](#-benchmark-environment--high-noise-real-world-dataset)
- [Performance Evaluation & Settings](#-performance-evaluation--settings)
- [Applied Results ‚Äî Pattern Recognition & Generalization](#-applied-results--pattern-recognition--generalization)
  - [Pattern Recognition on the Validation Set](#pattern-recognition-on-the-validation-set)
    - [Optimized Seeds (Validation)](#optimized-seeds)
    - [Random Seeds (Validation)](#random-seeds)
  - [Generalization on the Test Set](#generalization-on-the-test-set)
    - [Optimized Seeds (Test)](#optimized-seeds-1)
    - [Random Seeds (Test)](#random-seeds-1)
  - [Generalization, Robustness, and Consistency](#generalization-robustness-and-consistency)
- [Reproduction Package](#-reproduction-package)
  - [Quick Run](#-quick-run)
- [Additional Context](#additional-context)


</details>

## üîç Overview  

LMFO AI (Layered Multiple Frequency Optimization) is an **artificial-intuition‚Äìdriven decision support system** designed for real-world environments with **limited data and low signal-to-noise ratios (SNR)**. Through context-aware pattern recognition, LMFO distinguishes critical information from background noise and derives actionable patterns.  

<p align="center">
  <img src="media/diagrams/overview.PNG"
       alt="From noisy/limited data ‚Üí layered analysis ‚Üí context-aware pattern recognition ‚Üí decision support"
       width="500"><br>
  <sub><em>Weak signal &rarr; Contextual analysis &rarr; Strong pattern &rarr; Decision support</em></sub> 
</p>  

LMFO AI combines machine learning (ML) with metaheuristics, and goes further. It preserves **weak signals** that gain meaning in context (beyond ML‚Äôs strong-signal bias) and steers search with data-driven prioritization, adaptive search strategies (beyond random exploration in metaheuristics).  

Implemented in **Python** as a prototype, LMFO was **validated on public real-world datasets** with limited data and high noise. Extensive testing confirmed its ability to deliver consistent, robust, and generalizable results.  

Originally developed for **predictive maintenance and risk analytics**, its modular and scalable architecture enables seamless adaptation across domains ‚Äî including industrial automation, automotive, energy, finance, and bioinformatics ‚Äî where reliable insights under uncertainty are required.  

‚Üí **Problem:** High noise, limited data  
‚Üí **Solution:** Layered, data-driven, context-aware inference  
‚Üí **Proof:** Independent, statistically validated results showing generalization, robustness, and consistency

<details>
<summary><strong><em>LMFO Workflow At a Glance</em></strong></summary>
<p align="center">
  <img src="media/diagrams/algorithmic-steps.PNG"
       alt="LMFO workflow"
       width="550"><br>
  <sub><em>End-to-end workflow: from noisy data to validated patterns</em></sub> 
</p>
</details>

<details>
<summary><strong><em>LMFO Architecture At a Glance</em></strong></summary>
<p align="center">
  <img src="media/diagrams/layered-structure.PNG"
       alt="LMFO AI architecture: layered design for building patterns while preserving context."
       width="500"><br>
  <sub><em>Layered context pass (L1 &rarr; L3)</em></sub> 
</p>
  </details>

<details>
<summary><strong><em>LMFO Real-World Impact At a Glance</em></strong></summary>
<p align="center">
  <img src="media/diagrams/Conclusion.PNG"
       alt="LMFO pyramid: layered architecture and context-aware pattern recognition, built on a foundation of generalization, robustness, and consistency; applicable to domains such as risk analytics, predictive maintenance, cybersecurity, and smart grid management."
       width="400"><br>
  <sub><em>Reliable decision support in scarce data, high noise environments</em></sub> 
</p>
  </details>

---

## ‚ú® Key Features

- **Multi-Layer Architecture (L1 ‚Üí L2 ‚Üí L3)**  
  Progressively narrows large, noisy search spaces; each layer refines candidate patterns in a coarse-to-fine flow.

- **Context-Aware Inference (Strong + Weak Signals)**  
  Retains weak as well as strong signals; uses context to turn them into meaningful patterns.

- **Experience Transfer & Representation Balancing**  
  Transfers experience across runs ‚Äî using prior signal blocks as context ‚Äî and rebalances under-represented signals to preserve rare, high-value patterns.

- **Data-Driven Prioritization & Adaptive Search**  
  Ranks candidates by information value and relevance, focuses on high-potential regions, and redirects away from low-yield areas as feedback accumulates.

- **Relationship-Based Pattern Recognition**  
  Regroups signals by context to build richer patterns, and restores context-relevant features lost during reduction ‚Äî recovering diversity without increasing dimensionality.

- **Validated, Reproducible Prototype**  
  Independently tested on limited, high-noise real-world datasets; delivers robust, generalizable results.

---

## üìä Real-World Impact

<p align="center">
  <img src="media/diagrams/business-value.PNG"
       alt="From signals to LMFO analysis ‚Üí risk scoring ‚Üí decision support"
       width="450"><br>
  <sub><em>Real-world business value of LMFO AI</em></sub> 
</p>   

### Predictive Maintenance ‚Äî Risk Analysis & Early Warning
- **Problem** ‚Äî A line with ~100 sensors shows ~25 abnormal signals during a failure, but combinations vary each time (no single ‚Äúfailure signature‚Äù); the solution space is astronomical (~2√ó10^23).
- **LMFO‚Äôs contribution** ‚Äî From limited failure records, extracts **10-sensor indicator patterns**; issues **graded alerts** (5‚Äì6 = early, 7‚Äì8 = strong, 9‚Äì10 = critical), reducing false positives and anticipating unseen scenarios.
- **Business value** ‚Äî Industry reports for predictive maintenance cite **30‚Äì50% less unplanned downtime**, **20‚Äì40% longer equipment life**, **5‚Äì10% lower maintenance costs**, and **10‚Äì20% higher uptime** (McKinsey 2017; Deloitte 2017; PwC/Mainnovation 2018; Siemens‚ÄìSenseye case studies 2021‚Äì2024).

### Multi-Sector Adaptability
Feature-agnostic, layered architecture that generalizes across domains:
- **Cybersecurity (SOC / Threat Detection)** ‚Äî Surfaces **8 critical signatures** from ~90 log types; grades threat levels by partial matches.
- **Finance / Fraud Analytics** ‚Äî Extracts a **7-indicator pattern** from ~80 risk indicators; scores transaction flows in real time by match level.
- **Energy / Smart Grid** ‚Äî Finds **10 critical patterns** from ~75 parameters; anticipates and mitigates regional failures in advance.

---

## üß™ Benchmark Environment & High-Noise Real-World Dataset

- **Dataset** ‚Äî Public *On Numara* (‚ÄúNumber Ten‚Äù, Turkey): extremely low SNR, limited observations, and a vast combinatorial search space.

- **Problem framing** ‚Äî 80 items; 22 are active per event. The active items vary across events‚Äîthere is no single "critical signature". This creates high uncertainty at scale.

- **Challenges**
  - **Scale issue:** astronomical number of potential combinations ‚Äî **C(80,22) ‚âà 2.7√ó10¬π‚Åπ**
  - **Data issue:** only **~1.200** events observed ‚Äî **>99,99%** of the space remains unseen
  - **Noise issue:** weak yet context-relevant signals are easily lost

- **Real-World Relevance** ‚Äî Mirrors real-world cases where, under limited data and low SNR, critical event signatures must be identified through **indicative patterns**, even before all indicators fully emerge.

- **Indicative-pattern solution** ‚Äî Extract **10-element indicator patterns** from the 22 active items per event, yielding:
  1) **Scalability**: shrinks the search into a focused domain  
  2) **Focused visibility**: turns limited observations into a tractable solution space  
  3) **Signal preservation**: retains weak-but-contextual signals

<details>
<summary><strong><em>Scaling At a Glance</em></strong></summary>
<p align="center">
  <img src="media/diagrams/scaled-space.PNG"
       alt="LMFO ‚Äì Scaling astronomical search spaces, increasing data visibility, and preserving critical signals in the benchmark dataset."
       width="300"><br>
  <sub><em>From astronomical search space to a tractable solution space ‚Äî with large relative data gain.</em></sub> 
</p>
</details>

As pattern intensity increases, signals become exponentially rarer‚Äîhence sustaining performance at higher match levels (9/10‚Äì10/10) is especially challenging.  

<details>
<summary><strong><em>Pattern & Signal Intensity</em></strong></summary>
<p align="center">
  <img src="media/charts/signal-density.PNG"
       alt="LMFO ‚Äì Scaling astronomical search spaces, increasing data visibility, and preserving critical signals in the benchmark dataset."><br>
</p>
</details>

---

## üìà Performance Evaluation & Settings

- **Approach** ‚Äî Instead of parameter optimization, LMFO directly optimizes indicative patterns ‚Äî signals that may appear meaningless individually but gain significance in context. Performance is evaluated at the pattern level, not on individual signals.

- **Protocol**
  1) **Validation set** ‚Äî held out from training to get the first performance signal  
  2) **Test set** ‚Äî independent data to verify generalization  
  3) **Stepwise evaluation** ‚Äî assess performance across pattern-intensity buckets (e.g., 5/10 ‚Ä¶ 10/10) for consistency and robustness  
  4) **Joint assessment** ‚Äî compare validation vs test to confirm stability

<p align="center">
  <img src="media/diagrams/performance-evaluation.PNG"
       alt="Validation & test workflow ‚Äî statistical validation + stepwise performance ‚Üí generalization, robustness, consistency"
       width="500"><br>
  <sub><em>Validation & test workflow</em></sub>
</p>

- **Metrics**
  - **PRS (Pattern Recognition Score)** ‚Äî accuracy normalized by signal density (**>1** = above expected; **<1** = below)  
  - **EPS (Expected Pattern Score)** ‚Äî standardized scale with **baseline = 1** 
  - **Significance** ‚Äî one-tailed z-test, **p < 0,05**

- **Interpretation example**
  - 8/10 bucket: **PRS = 1,72** ‚Üí 72% above expected  
  - 9/10 bucket: **PRS = 0,95** ‚Üí 5% below expected

- **Initialization** ‚Äî Runs start either from scratch or with small seeds (3‚Äì4 items) to trigger context analysis from Layer 1.
- **Seeding regimes** ‚Äî Two core regimes are evaluated: **optimized seeds** (from prior runs) and **random seeds**; both are supplied as initial solutions.
- **Layered expansion** ‚Äî Seeds propagate across layers (L1‚ÜíL2‚ÜíL3) and consolidate into **10-item indicative patterns** via a coarse-to-fine flow.
- **Objectives:**
  1) assess pattern recognition under high noise
  2) test whether weak signals become strong in context
  3) verify extraction from random seeds
  4) check consistency across initial conditions
- **Evaluation setup** ‚Äî Multiple predefined configs; train on train, validate on val, test on test; results averaged across configs (metrics: **PRS**, **EPS**).

---

## üéØ Applied Results ‚Äî Pattern Recognition & Generalization

### Pattern Recognition on the Validation Set  

#### Optimized Seeds  

Across all signal densities (6/10‚Äì10/10), LMFO exceeds the expected baseline (EPS=1) with statistical significance (p < 0,05).  

<p align="center">
  <img src="media/charts/valid-optimized-graf.PNG">
</p>  

- 6/10‚Äì7/10 (high): **31‚Äì54%** higher score  
- 8/10 (medium): **81%** higher score  
- 9/10‚Äì10/10 (low): **√ó2,64** and **√ó8,12** higher score  

**Takeaway:** Patterns extracted under **low signal density achieved scores up to 8√ó higher** than the baseline (EPS = 1). This finding highlights LMFO‚Äôs mechanism of ‚Äúreconstructing weak signals within context‚Äù.  

**Note:** In the 10/10, random references deviated from baseline, but not significant (p = 0,2556).  

#### Random Seeds  

Across 6/10‚Äì9/10, results still remain above baseline (p < 0,05); but 10/10 not significant (p = 0,4325).  

<p align="center">
  <img src="media/charts/valid-random-graf.PNG">
</p>    

- 6/10‚Äì7/10 (high): **5‚Äì8%** higher score  
- 8/10 (medium): **19%** higher score  
- 9/10 (low): **86%** higher score  

**Takeaway:** Even with no prior information, **the strong performance at low signal density (86%)** demonstrates the algorithm‚Äôs ability to "quickly identify relevant signals" and "adaptively reorient the search". These results confirm LMFO‚Äôs **robustness** under high-noise and low-signal conditions.  

### Generalization on the Test Set

#### Optimized Seeds  

**Validation trends are preserved** on the independent data (6/10‚Äì9/10 significant at p < 0,05).  

<p align="center">
  <img src="media/charts/test-optimized-graf.PNG">
</p>  

- 6/10‚Äì7/10 (high): **30‚Äì34%** higher score    
- 8/10 (medium): **78%** higher score    
- 9/10 (low): **√ó2,68** higher score  

**Takeaway:** Context-aware inference **generalizes** beyond validation; stability holds across densities 6/10‚Äì9/10.  

**Note:** At the weakest signal density (10/10), no statistically significant difference was observed (p = 0,5956), likely due to the limited size of the test set.  

#### Random Seeds  

Generalization maintained across all signal densities in the 6/10‚Äì9/10 range even with random seeds (p < 0,05).  

<p align="center">
  <img src="media/charts/test-random-graf.PNG">
</p>    

- 6/10‚Äì7/10 (high): **5‚Äì18%** higher score    
- 8/10 (medium): **39%** higher score    
- 9/10 (low): **√ó2,80** higher score    
- 10/10 (weakest): **√ó7,36** higher score (significant at **90%**, p = 0,0691)

**Takeaway:** **Robustness** persists with random seeds; strongest lifts appear in low-signal regimes.

### Generalization, Robustness, and Consistency  

The table below summarizes the pattern scores and significance levels across the validation and test sets by density and seed type.  

<p align="center">
  <img src="media/charts/compare-table.PNG">
</p>    

LMFO extracts **stable, generalizable patterns** under both strong and weak contextual conditions.

<p align="center">
  <img src="media/charts/compare-graf.PNG">
</p>    

Pattern recognition performance of LMFO across different signal densities in the validation and test sets:

- **High & medium (6/10‚Äì8/10)**
  - **Optimized seeds:** Validation ‚âà Test (**1,30‚Äì1,81**).
  - **Random seeds:** Lower (**1,05‚Äì1,39**) yet above baseline; generalization preserved.  

- **Low (9/10‚Äì10/10)**
  - **Optimized seeds:** 9/10 strong & stable (**2,64 ‚Üí 2,68**); 10/10 strong on validation (**8,12**) but not significant on test.
  - **Random seeds:** 9/10 consistent & significant (**1,86 ‚Üí 2,80**); 10/10 not significant on validation (1,46) but **7,36√ó** on test (90% level).  

**Takeaway:** LMFO remains reliable under high noise and the **largest gains emerge as signal density decreases**. The **consistency** between validation and test sets demonstrates the algorithm‚Äôs ability to deliver **reliable and generalizable** results in challenging scenarios. Moreover, maintaining consistency across both different initialization conditions and varying signal densities strongly confirms LMFO‚Äôs **robustness**.

---

## üì¶ Reproduction Package

To ensure **full reproducibility and transparency**, all system files, control tools, and supplementary guides are included in:

‚û°Ô∏è [LMFO-AI_V01.zip](./LMFO-AI_V01.zip)

This package contains:
- **Python Core (L1‚ÄìL3 + Runner)** ‚Äî main LMFO algorithm
- **Control File** ‚Äî companion tool for data preparation, decoding, and validation/test workflows
- **Supplementary READMEs** ‚Äî detailed guides covering Control File usage, LMFO run procedures, and step-by-step validation/test reproduction
- **Benchmark Reports** ‚Äî Excel tables, charts, and screenshots of validation/test results

### ‚ö° Quick Run
The package is also pre-configured with a **quick run profile** (3 optimized seeds, short runtime).  
This allows users to **verify the workflow end-to-end** (run ‚Üí output ‚Üí validation) in just a few minutes, before moving on to full-scale runs with all seeds and profiles.

### ‚öôÔ∏è Requirements
- Python 3.9+  
- Packages: `numpy`, `pandas`, `imblearn`  

### ‚ñ∂Ô∏è How to Run
1. Clone the repository  
2. Run `RUN_LMFO.py`
3. Open `control_file-validation.xlsm` ‚Üí LMFO Tab ‚Üí click **Decode Set** and then **Test Set**

---

## Additional Context  

For readers interested in the architectural foundations, intuition-driven mechanisms, and real-world applications of LMFO‚Äîin particular, its conceptual ‚Äúartificial intuition‚Äù framework‚Äîcheck out this [detailed blog article](https://ishakkutlu.com/lmfo-ai-pattern-recognition-in-noisy-data-with-artificial-intuition/).  

It delves into the layered design, data-driven prioritization, validation pipeline, and business value in far greater depth than the README.  



